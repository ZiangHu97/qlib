

---

### **自动化因子表达式计算系统 - 开发启动手册 (V1.2)**

| 版本 | 日期       | 主要变更                                                                                                     | 作者     |
| :--- | :--------- | :----------------------------------------------------------------------------------------------------------- | :------- |
| 1.0  | 2023-10-26 | 初始版本，定义基本流程和模块。                                                                               | 系统架构师 |
| 1.1  | 2023-10-27 | 引入DAG、并行计算和缓存概念。                                                                                | 系统架构师 |
| 1.2  | 2023-10-27 | **重大更新**: 引入规划/执行分离架构；细化数据容器；定义Top-Down规划与Bottom-Up执行流程；明确公共子表达式消除和缓存短路机制。 | 系统架构师 |

---

#### 1. 设计哲学与核心原则

本系统旨在成为一个高性能、高可扩展的因子计算引擎。其设计遵循以下核心原则：

*   **规划与执行分离 (Planning vs. Execution)**: 系统严格分为两个阶段。**规划阶段**负责理解和优化计算任务（自顶向下），生成一个高效的执行蓝图（DAG）。**执行阶段**则完全根据此蓝图进行计算（自底向上），实现最大化的并行和资源利用。
*   **缓存优先 (Cache-First)**: 缓存是系统的一等公民。在规划阶段就进行缓存检查以实现计算短路，在执行阶段则将新结果写入缓存，最大限度地重用计算。
*   **接口驱动 (Interface-Driven)**: 系统的可扩展性源于其面向接口的设计。`DataProvider` 和 `DataContainer` 等核心组件都通过抽象接口定义，使得更换数据源或增加数据类型无需修改上层引擎。
*   **不变性与幂等性 (Immutability & Idempotence)**: 规划阶段生成的执行DAG是不可变的。对同一个表达式和上下文（如时间范围）的规划，其结果（DAG结构与节点ID）是幂等的。这为安全的并行计算、缓存和结果复现提供了坚实的基础。

#### 2. 系统架构总览

系统由四个松耦合的核心模块构成，它们协同完成从表达式到最终结果的转换。



1.  **`data_layer`**: 负责底层数据的抽象和加载。
2.  **`parser_planner`**: 负责解析表达式字符串，并构建一个经过优化的执行DAG。
3.  **`operators`**: 包含所有原子计算函数的纯函数库。
4.  **`engine`**: 负责调度执行DAG，管理并行计算和缓存。

#### 3. 核心流程详解

##### **Phase 1: 规划阶段 (Top-Down Analysis & Optimization)**

此阶段的目标是**"只思考，不计算"**。从用户输入的表达式开始，构建一个最优的执行计划。

*   **输入**: 表达式字符串 (e.g., `"add(rank(close), rank(close))"`), 时间范围 (`start_date`, `end_date`), 以及其他上下文。
*   **输出**: 一个信息完备、经过优化的执行DAG。

1.  **解析 (Parse)**: `parser`模块将表达式字符串转换为一个基础的、未优化的AST（抽象语法树）。这是一个纯粹的语法结构。

2.  **规划与优化 (Plan & Optimize)**: 这是V1.2架构的核心。`ExecutionPlanner`执行以下操作：
    a. **自顶向下遍历AST**: 从根节点开始，递归地访问每个节点。
    b. **节点唯一化与公共子表达式消除**: 对每个节点的规范化表达式（如`'rank(close)'`）进行哈希，生成唯一的`node_id`。规划器维护一个全局的`{node_id: DAGNode}`字典。当遇到一个新的子表达式时：
        *   如果其`node_id`已存在于字典中，则直接将当前父节点连接到已有的`DAGNode`上，实现**公共子表达式消除 (Common Subexpression Elimination)**。
        *   如果`node_id`不存在，则创建一个新的`DAGNode`并加入字典。
    c. **缓存短路 (Cache Short-Circuiting)**: 在创建新`DAGNode`之前，使用其`node_id`查询缓存系统。
        *   如果缓存命中，该节点被标记为`STATUS_CACHED`，并将其结果的引用存入节点。**关键：此时将不再继续向下遍历此分支**，实现了计算的"短路"。
    d. **元数据推导 (Metadata Inference)**: 在遍历过程中，父节点将上下文信息（如时间窗口需求）传递给子节点。例如，`ts_mean(expr, 10)`会告诉`expr`节点，它的数据需要在请求的时间范围基础上向前扩展9个周期。这些信息（如`required_window`, `data_type`）被记录在每个`DAGNode`的`metadata`中。叶子节点（如`close`）最终会根据这些元数据精确地知道需要从`DataProvider`加载什么数据。

##### **Phase 2: 执行阶段 (Bottom-Up Execution)**

此阶段的目标是**"只计算，不思考"**。严格按照规划好的DAG进行高效计算。

*   **输入**: 规划阶段生成的执行DAG。
*   **输出**: 根节点的最终计算结果 (`DataContainer`)。

1.  **拓扑排序与初始化**: `Scheduler`遍历最终的DAG，计算每个节点的**入度 (in-degree)**，即它依赖的节点数量。所有入度为0的节点（通常是叶子节点或被缓存命中的节点）被放入一个**"就绪队列" (Ready Queue)**。

2.  **调度与执行**: `Scheduler`启动一个循环：
    a. 从"就绪队列"中取出一个`DAGNode`。
    b. 如果节点状态为`STATUS_CACHED`，则直接跳到步骤 d。
    c. 否则，将其计算任务（调用相应的`operator`函数）提交到**工作线程池**。
    d. 任务完成后（通过`future`对象的回调函数），执行以下**传播 (Propagation)**逻辑：
        i.   将计算结果 (`DataContainer`) 存入**缓存**。
        ii.  更新当前`DAGNode`的状态为`STATUS_COMPLETED`。
        iii. 遍历当前节点的所有**父节点** (`parents`)。
        iv.  对于每个父节点，将其入度计数减1。
        v.   如果一个父节点的入度变为0，说明它的所有依赖都已完成，于是将该父节点加入"就绪队列"。

3.  **完成**: 当根节点的计算完成时，整个执行过程结束。调度器返回根节点的结果。

---

#### 4. 模块化设计与开发指南

##### **模块 1: `data_layer`**
*   **核心职责**: 提供标准化的数据加载接口和统一的数据内存表示。
*   **关键组件**:
    *   `DataProvider` (ABC): 定义`load(self, field: str, dates: list, stocks: list) -> DataContainer`接口。
    *   `ParquetDataProvider`: `DataProvider`的具体实现，处理`/tmp/daily/{date}.parquet`数据。
    *   `DataContainer` (ABC): 所有数据容器的基类。
    *   `PanelContainer(DataContainer)`: 用于存储面板数据 (Time x Stock)，使用`pd.DataFrame`实现，`index`为`datetime`，`columns`为`stock_id`。
    *   `CrossSectionContainer(DataContainer)`: 用于存储截面数据 (1 x Stock)，可用`pd.Series`实现。

##### **模块 2: `parser_planner`**
*   **核心职责**: 将表达式字符串转换为优化的执行DAG。
*   **关键组件**:
    *   `Parser`: 使用现成库（如PLY或Antlr）或手写一个简单的递归下降解析器，输出基础AST。
    *   `ExecutionPlanner`:
        *   **`plan(expression, context)`方法**: 实现Phase 1的完整逻辑。
        *   **`_get_node_id(sub_expression_str)`方法**: 实现规范化和哈希逻辑。

##### **模块 3: `operators`**
*   **核心职责**: 提供一组对`DataContainer`进行操作的纯函数。
*   **实现要点**:
    *   每个函数 (e.g., `def op_ts_mean(data: PanelContainer, window: int) -> PanelContainer:`) 都是无状态的。
    *   算子不应关心数据从何而来，只负责计算。

##### **模块 4: `engine`**
*   **核心职责**: 高效、并行地执行DAG。
*   **关键组件**:
    *   `Scheduler`:
        *   `ThreadPoolExecutor`: 用于管理工作线程。
        *   `collections.deque`: 作为"就绪队列"。
        *   `dict`: 存储每个节点的入度。
        *   `execute(dag_root_node)`方法: 实现Phase 2的完整逻辑。
    *   `Cache`:
        *   一个简单的接口，包含`get(key)`和`set(key, value)`。
        *   初期可使用内存字典`{}`实现，未来可轻松替换为Redis或Memcached。

---

#### 5. 核心数据结构定义

```python
from enum import Enum
from typing import Any, List, Dict

class NodeStatus(Enum):
    PENDING = "PENDING"
    READY = "READY"
    RUNNING = "RUNNING"
    COMPLETED = "COMPLETED"
    CACHED = "CACHED"
    FAILED = "FAILED"

class DAGNode:
    def __init__(self, expression: str, operator: str, args: List[Any]):
        # --- 规划阶段填充 (Immutable after planning) ---
        self.id: str = self._generate_id(expression, operator, args) # Unique hash
        self.expression: str = expression
        self.operator: str = operator # e.g., 'ts_mean', 'rank', 'load_data'
        self.dependencies: List['DAGNode'] = [] # Children nodes
        self.parents: List['DAGNode'] = [] # Parent nodes (for propagation)
        
        # --- 元数据 (Filled during planning) ---
        self.metadata: Dict[str, Any] = {
            'required_window': 0,
            'data_type_hint': None,
            # ... other inferred metadata
        }

        # --- 执行阶段状态 (Mutable during execution) ---
        self.status: NodeStatus = NodeStatus.PENDING
        self.result_ref: Any = None # Reference to the result in cache or memory

```

---

#### 6. 开发路线图

1.  **Milestone 1: 基础框架与数据层 (Foundation)**
    *   [ ] 定义 `DAGNode` 类结构。
    *   [ ] 定义 `DataProvider` 和 `DataContainer` 的抽象基类。
    *   [ ] 实现 `PanelContainer`。
    *   [ ] 实现 `ParquetDataProvider`。
    *   [ ] 编写单元测试，确保数据加载正确。

2.  **Milestone 2: 规划器与核心算子 (Planner & Operators)**
    *   [x] 实现一个简单的 `Parser`。
    *   [x] **(核心)** 实现 `ExecutionPlanner`，重点是**节点唯一化**和**公共子表达式消除**。
    *   [x] 实现 `op_add`, `op_divide`, `op_ts_mean`, `op_rank` 几个核心算子。
    *   [x] 编写测试，验证 `planner` 能为 `add(rank(close), rank(close))` 生成正确的、包含节点重用DAG。

3.  **Milestone 3: 调度器与并行执行 (Scheduler)**
    *   [ ] 实现基于入度和就绪队列的 `Scheduler`。
    *   [ ] 集成 `ThreadPoolExecutor`。
    *   [ ] 编写集成测试，将 `Planner` 的输出喂给 `Scheduler`，验证端到端流程。
    *   [ ] 编写性能测试，验证 `add(slow_op(1), slow_op(2))` 的并行加速效果。

4.  **Milestone 4: 缓存与完整系统 (Caching & Integration)**
    *   [ ] 实现一个内存 `Cache` 模块。
    *   [ ] 在 `ExecutionPlanner` 中集成缓存检查逻辑（短路）。
    *   [ ] 在 `Scheduler` 的回调中集成缓存写入逻辑。
    *   [ ] 编写完整的集成测试，覆盖缓存命中、未命中、公共子表达式消除等所有场景。

---

#### 7. 附录：示例演练

**表达式**: `divide(ts_mean(close, 5), ts_mean(close, 5))`

1.  **规划阶段**:
    *   `Planner` 从 `divide` 开始。它有两个子节点，都是 `ts_mean(close, 5)`。
    *   处理第一个 `ts_mean(close, 5)`：计算其ID（如`hash('ts_mean(close,5)')` -> `ID_A`）。`Planner`发现`ID_A`是新的，于是创建`Node_A`。
    *   `Node_A`需要`close`数据，并且需要5天窗口。它将这个元数据向下传递。
    *   处理`close`：计算其ID（`ID_B`），创建`Node_B`，并记录元数据（需要加载`close`字段，且回溯期至少为4天）。`Node_B`成为`Node_A`的依赖。
    *   处理第二个 `ts_mean(close, 5)`：计算其ID，**得到相同的`ID_A`**。`Planner`发现`Node_A`已存在，于是直接将`divide`节点的第二个依赖指向现有的`Node_A`。
    *   **最终DAG**: `Node_Divide` -> `Node_A` -> `Node_B` (其中`Node_A`被`Node_Divide`引用两次，但它是一个单一的节点)。

2.  **执行阶段**:
    *   `Scheduler` 计算入度：`Node_B`=0, `Node_A`=1, `Node_Divide`=1 (注意：即使被引用两次，依赖的是同一个节点，所以入度是1)。
    *   `Node_B` (`close`) 进入就绪队列并被执行。
    *   `Node_B`完成后，`Node_A`的入度减为0，进入就绪队列并被执行。**`ts_mean`只被计算一次**。
    *   `Node_A`完成后，`Node_Divide`的入度减为0，进入就绪队列并被执行。
    *   返回最终结果。

这份手册提供了清晰的蓝图和行动路径。我们可以从 **Milestone 1** 开始，动手编写代码。

